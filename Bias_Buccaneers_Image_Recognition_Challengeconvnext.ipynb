{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6Lv5OYlsx7Vz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b17d4b48-6a92-4060-b49a-31fc18a44b20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/data_bb1_img_recognition.zip /content/"
      ],
      "metadata": {
        "id": "mdIzGvkwMta3"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip data_bb1_img_recognition.zip -d /content/dataset/"
      ],
      "metadata": {
        "id": "oMOks48_M2Fh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install tensorflow\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import json\n",
        "import os\n",
        "\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "import tensorflow as tf\n",
        "print(tf. __version__)\n",
        "import tensorflow.keras as K\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.resnet_v2 import ResNet101V2\n",
        "from tensorflow.keras.applications.convnext import ConvNeXtLarge"
      ],
      "metadata": {
        "id": "vKgnknGKMq9m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4d1b81d-dc27-4d82-e60e-b20961e5c99f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.11.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load data\n",
        "LOADPATH = '/content/dataset/train/'\n",
        "SAVEPATH = '/content/models/'\n",
        "df = pd.read_csv(LOADPATH+'labels.csv')\n",
        "df_labeled = df[df[\"skin_tone\"].notna()] # take only labeled data\n",
        "\n",
        "# Converting labels to np array\n",
        "cat = ['skin_tone','gender','age']\n",
        "lbs = [LabelBinarizer() for i in range(3)]\n",
        "Y = []\n",
        "for i in range(3):\n",
        "    lab = lbs[i].fit_transform(df_labeled[cat[i]])\n",
        "    if lab.shape[1]==1:\n",
        "        Y.append(np.hstack((1-lab,lab)))\n",
        "    else:\n",
        "        Y.append(lab)"
      ],
      "metadata": {
        "id": "9aFjeTbpNXJx"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install --upgrade tensorflow"
      ],
      "metadata": {
        "id": "kbPO8IWMm7YO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading and converting data into np array\n",
        "print(\"Loading images\")\n",
        "length = width = 64 # size for each input image, increase if you want\n",
        "nn = df_labeled.shape[0]\n",
        "all_imgs = [image.load_img(LOADPATH+df_labeled.iloc[i]['name'], target_size=(length,width)) for i in range(nn)]\n",
        "\n",
        "print(\"Converting images to np array\")\n",
        "X = np.empty([nn, length, width, 3], dtype=float)\n",
        "for i in range(nn):\n",
        "    X[i,:] = image.img_to_array(all_imgs[i])\n",
        "X = K.applications.convnext.preprocess_input(X)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xKVO-pTBScot",
        "outputId": "38602878-ddec-4a69-dbeb-827068cc9547"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading images\n",
            "Converting images to np array\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_imgs[1234] # print a test image"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "QGOff17MTN7Q",
        "outputId": "ddb99dd3-4204-4026-fac8-b232d2dd60c9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=64x64 at 0x7FBA93ED7E50>"
            ],
            "image/png": "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\n"
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class PredictionModel():\n",
        "    def __init__(self, X, Y, idx):\n",
        "        self.X = X\n",
        "        self.Y = Y\n",
        "        self.idx = idx\n",
        "        self.trainX, self.testX = X[idx[0],:], X[idx[1],:]\n",
        "        self.trainY, self.testY = [Y[i][idx[0],:] for i in range(3)], [Y[i][idx[1],:] for i in range(3)]\n",
        "        self.cat = ['skin_tone','gender','age']\n",
        "        self.loss = ['categorical_crossentropy' for i in range(3)]\n",
        "        self.metrics = [['accuracy'] for i in range(3)]\n",
        "        self.models = [None]*3\n",
        "\n",
        "    # train a model specific for a certain class index in self.cat\n",
        "    def fit(self, index, model, epochs=5, batch_size=16, save=False, save_location=None, verbose=1):\n",
        "        \n",
        "        if verbose: print(\"Training model for \"+self.cat[index])\n",
        "        model.add(K.layers.Dense(self.trainY[index].shape[1], activation='softmax'))\n",
        "        model.compile(loss=self.loss[index], optimizer='Adam', metrics=self.metrics[index])\n",
        "        model.fit(\n",
        "            self.trainX, self.trainY[index], \n",
        "            validation_data=(self.testX,self.testY[index]), \n",
        "            batch_size=batch_size, epochs=epochs, verbose=verbose\n",
        "        )\n",
        "        if save:\n",
        "            if os.path.exists(SAVEPATH)==False:\n",
        "                print('save location '+SAVEPATH+' did not exist. creating')\n",
        "                os.makedirs(SAVEPATH)\n",
        "            SAVE_LOCATION = save_location+'model_'+cat[index]+'.h5'\n",
        "            print(\"saving model at \"+SAVE_LOCATION)\n",
        "            model.save(SAVE_LOCATION)\n",
        "        self.models[index] = model\n",
        "            \n",
        "    def predict(self, newX):\n",
        "        predictions = [model.predict(newX) for model in self.models]\n",
        "        return predictions\n"
      ],
      "metadata": {
        "id": "kfHk1xG0bNAr"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to initialize a model\n",
        "def initializeModel():\n",
        "    res_model = ConvNeXtLarge(include_top=False, weights='imagenet', input_tensor=K.Input(shape=[length, width, 3]))\n",
        "\n",
        "    # # freeze all but the last layer\n",
        "    for layer in res_model.layers[:292]:\n",
        "      layer.trainable = False\n",
        "    model = K.models.Sequential()\n",
        "    model.add(res_model)\n",
        "    model.add(K.layers.Flatten())\n",
        "    model.add(K.layers.BatchNormalization())\n",
        "    model.add(K.layers.Dense(256, activation='relu'))\n",
        "    model.add(K.layers.Dropout(0.5))\n",
        "    model.add(K.layers.BatchNormalization())\n",
        "    model.add(K.layers.Dense(128, activation='relu'))\n",
        "    model.add(K.layers.Dropout(0.5))\n",
        "    model.add(K.layers.BatchNormalization())\n",
        "    model.add(K.layers.Dense(64, activation='relu'))\n",
        "    model.add(K.layers.Dropout(0.5))\n",
        "    model.add(K.layers.BatchNormalization())\n",
        "    return model\n",
        "\n",
        "nntrain = int(0.7*nn)\n",
        "np.random.seed(42)\n",
        "indices = np.random.permutation(nn)\n",
        "train_idx, test_idx = indices[:nntrain], indices[nntrain:]\n",
        "mymodel = PredictionModel(X=X, Y=Y, idx=[train_idx,test_idx])\n",
        "\n",
        "# train model\n",
        "for i in range(3):\n",
        "    mymodel.fit(index=i, model=initializeModel(), epochs=5, save=True, save_location=SAVEPATH)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CRbjLLoMbO77",
        "outputId": "8ab8bba7-ae59-4b59-cc68-1af34acda6ca"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training model for skin_tone\n",
            "Epoch 1/5\n",
            "375/375 [==============================] - 73s 134ms/step - loss: 2.5191 - accuracy: 0.1545 - val_loss: 1.9496 - val_accuracy: 0.2580\n",
            "Epoch 2/5\n",
            "375/375 [==============================] - 49s 132ms/step - loss: 2.1500 - accuracy: 0.1989 - val_loss: 1.8443 - val_accuracy: 0.2689\n",
            "Epoch 3/5\n",
            "375/375 [==============================] - 49s 131ms/step - loss: 1.9990 - accuracy: 0.2228 - val_loss: 1.7976 - val_accuracy: 0.2860\n",
            "Epoch 4/5\n",
            "375/375 [==============================] - 49s 130ms/step - loss: 1.9293 - accuracy: 0.2455 - val_loss: 1.7759 - val_accuracy: 0.2935\n",
            "Epoch 5/5\n",
            "375/375 [==============================] - 51s 135ms/step - loss: 1.8905 - accuracy: 0.2564 - val_loss: 1.7669 - val_accuracy: 0.3036\n",
            "save location /content/models/ did not exist. creating\n",
            "saving model at /content/models/model_skin_tone.h5\n",
            "Training model for gender\n",
            "Epoch 1/5\n",
            "375/375 [==============================] - 73s 144ms/step - loss: 0.6063 - accuracy: 0.7075 - val_loss: 0.3525 - val_accuracy: 0.8164\n",
            "Epoch 2/5\n",
            "375/375 [==============================] - 49s 130ms/step - loss: 0.4495 - accuracy: 0.7743 - val_loss: 0.3431 - val_accuracy: 0.8336\n",
            "Epoch 3/5\n",
            "375/375 [==============================] - 51s 136ms/step - loss: 0.4212 - accuracy: 0.7917 - val_loss: 0.3391 - val_accuracy: 0.8320\n",
            "Epoch 4/5\n",
            "375/375 [==============================] - 49s 131ms/step - loss: 0.4052 - accuracy: 0.8026 - val_loss: 0.3446 - val_accuracy: 0.8250\n",
            "Epoch 5/5\n",
            "375/375 [==============================] - 49s 130ms/step - loss: 0.3899 - accuracy: 0.8039 - val_loss: 0.3408 - val_accuracy: 0.8289\n",
            "saving model at /content/models/model_gender.h5\n",
            "Training model for age\n",
            "Epoch 1/5\n",
            "375/375 [==============================] - 73s 144ms/step - loss: 1.3621 - accuracy: 0.4476 - val_loss: 0.9209 - val_accuracy: 0.6033\n",
            "Epoch 2/5\n",
            "375/375 [==============================] - 49s 130ms/step - loss: 1.0557 - accuracy: 0.5458 - val_loss: 0.9008 - val_accuracy: 0.6083\n",
            "Epoch 3/5\n",
            "375/375 [==============================] - 49s 130ms/step - loss: 1.0035 - accuracy: 0.5629 - val_loss: 0.8708 - val_accuracy: 0.6247\n",
            "Epoch 4/5\n",
            "375/375 [==============================] - 49s 129ms/step - loss: 0.9569 - accuracy: 0.5814 - val_loss: 0.8560 - val_accuracy: 0.6274\n",
            "Epoch 5/5\n",
            "375/375 [==============================] - 49s 129ms/step - loss: 0.9276 - accuracy: 0.5926 - val_loss: 0.8496 - val_accuracy: 0.6259\n",
            "saving model at /content/models/model_age.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load labels data\n",
        "TESTPATH = '/content/dataset/test/'\n",
        "df_test = pd.read_csv(TESTPATH+'labels.csv')\n",
        "\n",
        "# Convert labels to np array\n",
        "print(\"Converting test labels to np array\")\n",
        "testY = []\n",
        "for i in range(3):\n",
        "    lab = lbs[i].fit_transform(df_test[cat[i]])\n",
        "    if lab.shape[1]==1:\n",
        "        testY.append(np.hstack((1-lab,lab)))\n",
        "    else:\n",
        "        testY.append(lab)\n",
        "        \n",
        "# load and convert images into np array\n",
        "print(\"Loading test images\")\n",
        "nt = df_test.shape[0]\n",
        "all_imgs = [image.load_img(TESTPATH+df_test.iloc[i]['name'], target_size=(length,width)) for i in range(nt)]\n",
        "\n",
        "print(\"Converting test images to np array\")\n",
        "testX = np.empty([nt, length, width, 3], dtype=float)\n",
        "for i in range(nt):\n",
        "    testX[i,:] = image.img_to_array(all_imgs[i])\n",
        "testX = K.applications.convnext.preprocess_input(testX)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f-g0dtc1bQ4P",
        "outputId": "033aafce-2bab-4ab4-9f98-12aaae59ca7f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converting test labels to np array\n",
            "Loading test images\n",
            "Converting test images to np array\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred = mymodel.predict(testX)\n",
        "predY = [[np.argmax(pred[i][j,:]) for j in range(nt)] for i in range(3)]\n",
        "predLabels = [[lbs[i].classes_[j] for j in predY[i]] for i in range(3)]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9XNefOcrbXmG",
        "outputId": "eb98e39d-fde1-485a-ebff-977725482f14"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "94/94 [==============================] - 18s 131ms/step\n",
            "94/94 [==============================] - 17s 123ms/step\n",
            "94/94 [==============================] - 16s 124ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate accuracy\n",
        "acc = {}\n",
        "for i in range(3):\n",
        "    icat = cat[i]\n",
        "    iacc = accuracy_score(df_test[cat[i]], predLabels[i])\n",
        "    acc[icat] = iacc\n",
        "\n",
        "# calculate disparity\n",
        "def disparity_score(ytrue, ypred):\n",
        "    cm = confusion_matrix(ytrue,ypred)\n",
        "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "    all_acc = list(cm.diagonal())\n",
        "    return max(all_acc) - min(all_acc)\n",
        "\n",
        "disp = {}\n",
        "for i in range(3):\n",
        "    icat = cat[i]\n",
        "    idisp = disparity_score(df_test[cat[i]], predLabels[i])\n",
        "    disp[icat] = idisp\n",
        "disp\n",
        "\n",
        "results = {'accuracy': acc, 'disparity': disp}\n",
        "results\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tdbd2uM0bYBc",
        "outputId": "2dc57b1d-1f06-4787-c345-6a9f343bfcfb"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': {'skin_tone': 0.2936666666666667,\n",
              "  'gender': 0.8676666666666667,\n",
              "  'age': 0.652},\n",
              " 'disparity': {'skin_tone': 0.5921052631578947,\n",
              "  'gender': 0.2262231056247166,\n",
              "  'age': 0.735916777114596}}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def getScore(results):\n",
        "    acc = results['accuracy']\n",
        "    disp = results['disparity']\n",
        "    ad = 2*acc['gender']*(1-disp['gender']) + 4*acc['age']*(1-disp['age']**2) + 10*acc['skin_tone']*(1-disp['skin_tone']**5)\n",
        "    return ad\n",
        "\n",
        "title = '8-Bit Bias Bounty Baseline'\n",
        "    \n",
        "submission = {\n",
        "    'submission_name': title,\n",
        "    'score': getScore(results),\n",
        "    'metrics': results\n",
        "}\n",
        "submission"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0twNHvlbZUw",
        "outputId": "0c88a24a-c63e-468d-9e75-1353ef61209d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'submission_name': '8-Bit Bias Bounty Baseline',\n",
              " 'score': 5.261281793120094,\n",
              " 'metrics': {'accuracy': {'skin_tone': 0.2936666666666667,\n",
              "   'gender': 0.8676666666666667,\n",
              "   'age': 0.652},\n",
              "  'disparity': {'skin_tone': 0.5921052631578947,\n",
              "   'gender': 0.2262231056247166,\n",
              "   'age': 0.735916777114596}}}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"evad_score.json\", \"w\") as f:\n",
        "    json.dump(submission, f, indent=4)"
      ],
      "metadata": {
        "id": "5XL-HPlD9DVF"
      },
      "execution_count": 15,
      "outputs": []
    }
  ]
}